# Stable-Diffusion

## Problem Statement

The popularity of text-to-image models has spurned an entire new field of prompt engineering. Part art and part unsettled science, ML practitioners and researchers are rapidly grappling with understanding the relationships between prompts and the images they generate and in this project we aim to reverse the typical direction of a generative text-to-image model: instead of generating an image from a text prompt, can you create a model which can predict the text prompt given a generated image? You will make predictions on a dataset containing a wide variety of (prompt, image) pairs generated by Stable Diffusion 2.0, in order to understand how reversible the latent relationship is.
## Introduction

Stable Diffusion is a powerful tool that uses advanced image processing techniques to generate creative and thought-provoking prompts from images. This README file provides an overview of the Stable Diffusion system, including installation instructions, usage guidelines, and important information for users.

## Dataset

- For training the model I used the dataset from Hugging face - Poloclub/diffusiondb
- Dataset  https://huggingface.co/datasets/poloclub/diffusiondb/viewer/2m_first_5k/train
  
## Model

- I used gpt2 model for converting prompts to embeddings
- I used a pre trained model ResNet-18 for training the model
